{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pyenv/versions/3.6.5/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import bootstrapped.bootstrap as bs\n",
    "import bootstrapped.stats_functions as bs_stats\n",
    "from stable_baselines.results_plotter import ts2xy\n",
    "from stable_baselines.bench.monitor import load_results\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = 'ppo2' # \"sac\"\n",
    "env = \"Acrobot-v1\" #'CartPole-v1' 'RoboschoolInvertedPendulumSwingup-v1' \"RoboschoolAnt-v1\"  \"RoboschoolHopper-v1\"  \"LunarLanderContinuous-v2\"\n",
    "total_timesteps = int(2e5) # int(2e6)\n",
    "prefixes =  ['4sources-3sets-SIW'] #[\"1sources-3sets-SDW\", \"4sources-3sets-SDW\", \"4sources-3sets-SIW-no-bias\"] #\"1sources-3sets-SIW\", \"4sources-3sets-SIW\" \"1sources-3sets-1subopt-SIW\" \"4sources-3sets-2subopt-SIW\", \"4sources-3sets-4subopt-SIW\" \"8sources-3sets-SIW\"\n",
    "\n",
    "base = 'logs'\n",
    "save_path = \"{}/{}_analysis/\".format(base, env)\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute mean episodic rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_mean_episodic_reward(result, steps_percentage, total_timesteps=None):\n",
    "    \n",
    "    timesteps = result[0]\n",
    "    if total_timesteps is None:\n",
    "        total_timesteps = timesteps[-1]\n",
    "    cut_off = int(total_timesteps * steps_percentage)\n",
    "    \n",
    "    \n",
    "    if timesteps[-1] / cut_off < .95:\n",
    "        print(timesteps[-1] / cut_off,  timesteps[-1])\n",
    "        raise Warning(\"total_timesteps {} is too high comparing to trained timesteps {}\".format(total_timesteps, timesteps[-1]))\n",
    "    \n",
    "    # find cut_off episode\n",
    "    for cut_ind in reversed(range(len(timesteps))):\n",
    "        if timesteps[cut_ind] <= cut_off:\n",
    "            break\n",
    "    \n",
    "    return result[1][:cut_ind].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [02:37<00:00,  9.54it/s]\n"
     ]
    }
   ],
   "source": [
    "mean_episodic_reward = defaultdict(list)\n",
    "failed_exp = defaultdict(list)\n",
    "for env_exp_id in tqdm(os.listdir('logs/{}'.format(algo))):\n",
    "    if env in env_exp_id and env_exp_id[-1]=='1':\n",
    "        # remove the experiment number\n",
    "        env_exp = env_exp_id[:-2]\n",
    "        for i in range(1,4):\n",
    "            # load results of training from scratch\n",
    "            try:\n",
    "                result = ts2xy(load_results(\"logs/{}/{}_{}\".format(algo, env_exp, i)), 'timesteps')\n",
    "            except:\n",
    "                print((\"logs/{}/{}_{}\".format(algo, env_exp, i)))\n",
    "            for steps_percentage in [0.25, 0.5, 0.75, 1.0]:\n",
    "                mean_episodic_reward[algo+'_{}%'.format(int(steps_percentage*100))].append(\n",
    "                    _get_mean_episodic_reward(result, steps_percentage, total_timesteps))\n",
    "            \n",
    "        # get the experiment name\n",
    "        exp = ''.join(env_exp.split('_')[1:])\n",
    "        for p in prefixes:\n",
    "            for i in range(1,10):\n",
    "                file = \"{}/multipolar-{}/{}_{}-{}_{}\".format(base, algo, env, p, exp, i)\n",
    "                try:\n",
    "                    result = ts2xy(load_results(file), 'timesteps')\n",
    "                    for steps_percentage in [0.25, 0.5, 0.75, 1.0]:\n",
    "                        mean_episodic_reward['multipolar-{}_{}_{}%'.format(algo, p, int(steps_percentage*100))].append(\n",
    "                            _get_mean_episodic_reward(result, steps_percentage, total_timesteps))\n",
    "                except:\n",
    "                    failed_exp['multipolar-{}_{}'.format(algo, p)].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlap-ppo2_16sources-3sets-SIW ['logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg045-foot037-thigh048-torso031-size096-damping284-friction081-armature069_7', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg045-foot037-thigh048-torso031-size096-damping284-friction081-armature069_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg048-foot04-thigh035-torso042-size094-damping265-friction191-armature152_8', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg048-foot04-thigh035-torso042-size094-damping265-friction191-armature152_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg054-foot034-thigh044-torso034-size076-damping088-friction148-armature07_8', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg054-foot034-thigh044-torso034-size076-damping088-friction148-armature07_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg044-foot036-thigh046-torso038-size109-damping085-friction081-armature074_5', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg044-foot036-thigh046-torso038-size109-damping085-friction081-armature074_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg04-foot036-thigh051-torso031-size103-damping083-friction196-armature12_8', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg04-foot036-thigh051-torso031-size103-damping083-friction196-armature12_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg064-foot041-thigh049-torso03-size081-damping092-friction094-armature067_8', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg064-foot041-thigh049-torso03-size081-damping092-friction094-armature067_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg052-foot047-thigh041-torso043-size075-damping30-friction093-armature077_8', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg052-foot047-thigh041-torso043-size075-damping30-friction093-armature077_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg052-foot029-thigh051-torso03-size097-damping144-friction16-armature194_4', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg052-foot029-thigh051-torso03-size097-damping144-friction16-armature194_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg056-foot039-thigh054-torso042-size086-damping262-friction052-armature095_7', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg056-foot039-thigh054-torso042-size086-damping262-friction052-armature095_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg054-foot034-thigh047-torso038-size075-damping154-friction135-armature138_5', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg054-foot034-thigh047-torso038-size075-damping154-friction135-armature138_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg055-foot038-thigh049-torso047-size109-damping349-friction051-armature103_8', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg055-foot038-thigh049-torso047-size109-damping349-friction051-armature103_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg05-foot029-thigh039-torso038-size084-damping212-friction091-armature138_4', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg05-foot029-thigh039-torso038-size084-damping212-friction091-armature138_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg043-foot031-thigh036-torso036-size08-damping209-friction152-armature154_5', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg043-foot031-thigh036-torso036-size08-damping209-friction152-armature154_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg038-foot029-thigh037-torso042-size108-damping396-friction111-armature074_8', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg038-foot029-thigh037-torso042-size108-damping396-friction111-armature074_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg045-foot047-thigh052-torso03-size08-damping206-friction065-armature102_1', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg045-foot047-thigh052-torso03-size08-damping206-friction065-armature102_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg052-foot042-thigh048-torso048-size07-damping276-friction14-armature138_5', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg052-foot042-thigh048-torso048-size07-damping276-friction14-armature138_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg047-foot035-thigh035-torso044-size074-damping262-friction155-armature145_8', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg047-foot035-thigh035-torso044-size074-damping262-friction155-armature145_9', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg052-foot031-thigh054-torso048-size085-damping134-friction087-armature122_1', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg052-foot031-thigh054-torso048-size085-damping134-friction087-armature122_4', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg052-foot031-thigh054-torso048-size085-damping134-friction087-armature122_8', 'logs/mlap-ppo2/RoboschoolHopper-v1_16sources-3sets-SIW-leg052-foot031-thigh054-torso048-size085-damping134-friction087-armature122_9'] 38\n"
     ]
    }
   ],
   "source": [
    "for model in failed_exp:\n",
    "    print(model, failed_exp[model], len(failed_exp[model]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppo2_25% exists\n",
      "ppo2_50% exists\n",
      "ppo2_75% exists\n",
      "ppo2_100% exists\n",
      "saved mlap-ppo2_16sources-3sets-SIW_25%\n",
      "saved mlap-ppo2_16sources-3sets-SIW_50%\n",
      "saved mlap-ppo2_16sources-3sets-SIW_75%\n",
      "saved mlap-ppo2_16sources-3sets-SIW_100%\n"
     ]
    }
   ],
   "source": [
    "for model in mean_episodic_reward.keys():\n",
    "    file = os.path.join(save_path, model + '-{}.pkl'.format(total_timesteps))\n",
    "    if os.path.isfile(file):\n",
    "        print(\"{} exists\".format(model))\n",
    "        continue\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(mean_episodic_reward[model], f, pickle.HIGHEST_PROTOCOL)\n",
    "        print(\"saved {}\".format(model))\n",
    "        \n",
    "    file = os.path.join(save_path, model[:-5] + 'failed_exp.pkl')\n",
    "    if os.path.isfile(file):\n",
    "        with file as f:\n",
    "            pickle.dump(failed_exp[model], f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_episodic_reward = {}\n",
    "failed_exp = {}\n",
    "for model in os.listdir(save_path):\n",
    "    file = os.path.join(save_path, model)\n",
    "    if file[-4:] == '.pkl':\n",
    "        with open(file, 'rb') as f:\n",
    "            if 'failed' in file:\n",
    "                failed_exp[model[:-4]] = pickle.load(f)\n",
    "            else:\n",
    "                mean_episodic_reward[model[:-4]] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppo2_25% 26 (25,27)\n",
      "ppo2_50% 43 (42,45)\n",
      "ppo2_75% 67 (64,70)\n",
      "ppo2_100% 92 (88,96)\n",
      "mlap-ppo2_16sources-3sets-SIW_25% 78 (75,80)\n",
      "mlap-ppo2_16sources-3sets-SIW_50% 177 (172,182)\n",
      "mlap-ppo2_16sources-3sets-SIW_75% 272 (264,279)\n",
      "mlap-ppo2_16sources-3sets-SIW_100% 357 (348,367)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1993)\n",
    "for key in mean_episodic_reward:\n",
    "    cleanedList = [x for x in mean_episodic_reward[key] if str(x) != 'nan']\n",
    "    # print(key, str(round(np.mean(mean_episodic_reward[key]), 2)) + \" ± \" + str(round( 1.96 * np.std(mean_episodic_reward[key])/10, 2)) )\n",
    "    bounds = bs.bootstrap(np.array(cleanedList), stat_func=bs_stats.mean)\n",
    "    print(key, int(round(bounds.value)), \"({},{})\".format(int(round(bounds.lower_bound)), int(round(bounds.upper_bound))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppo2_25% 300\n",
      "ppo2_50% 300\n",
      "ppo2_75% 300\n",
      "ppo2_100% 300\n",
      "mlap-ppo2_8sources-3sets-SIW_25% 802\n",
      "mlap-ppo2_8sources-3sets-SIW_50% 802\n",
      "mlap-ppo2_8sources-3sets-SIW_75% 802\n",
      "mlap-ppo2_8sources-3sets-SIW_100% 802\n"
     ]
    }
   ],
   "source": [
    "for key in mean_episodic_reward:\n",
    "    print(key, len(mean_episodic_reward[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ppo2_25%', 'ppo2_50%', 'ppo2_75%', 'ppo2_100%', 'mlap-ppo2_4sources-3sets-4subopt-SIW_25%', 'mlap-ppo2_4sources-3sets-4subopt-SIW_50%', 'mlap-ppo2_4sources-3sets-4subopt-SIW_75%', 'mlap-ppo2_4sources-3sets-4subopt-SIW_100%'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_episodic_reward.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
